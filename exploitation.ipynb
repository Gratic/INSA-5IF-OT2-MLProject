{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation\n",
    "\n",
    "Goal is to exploit a model we trained to detect faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from cv2 import IMREAD_GRAYSCALE, IMREAD_COLOR\n",
    "from deep_learning_project.load_data import get_transform\n",
    "from deep_learning_project.net import LinearRegressionNetwork, SecondNeuralNetwork\n",
    "from torch import nn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model.\n",
    "\n",
    "Models are stocked in the models/ folder.\n",
    "\n",
    "The right model must be instanciated !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SecondNeuralNetwork()\n",
    "\n",
    "model.load_state_dict(torch.load('models/20221026_1659_SecondNeuralNetwork/best_test_weights.pt'))\n",
    "model.eval()\n",
    "\n",
    "classes = ['noface', 'face']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    obj = None\n",
    "    with torch.no_grad():\n",
    "        # exploit the model\n",
    "        logits = model(img)\n",
    "        pred_probab = nn.Softmax(dim=1)(logits)\n",
    "        y_pred = pred_probab.argmax(1).item() # indice(s) of the maximum value in the tensor\n",
    "        obj = (y_pred, pred_probab)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding faces on an image\n",
    "\n",
    "We load an image both color and greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 664, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image\n",
    "img_src = cv.samples.findFile(\"image2.jpg\")\n",
    "\n",
    "img = cv.imread(img_src, IMREAD_GRAYSCALE)\n",
    "img_color = cv.imread(img_src, IMREAD_COLOR)\n",
    "\n",
    "print(img_color.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to transform the image in a comprehensible way for the neural network. (do we ?)\n",
    "\n",
    "For that, we take the transformation used in the training. (get_transform()).\n",
    "Because we loaded the image through OpenCV and not PyTorch we have to transform the numpy format (H x W x C) into the PIL format with the ToPILImage transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 442, 664])\n"
     ]
    }
   ],
   "source": [
    "# Transform the image\n",
    "transform = get_transform()\n",
    "\n",
    "transformed_image = transform(T.ToPILImage()(img_color))\n",
    "print(transformed_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to find the faces in the image !\n",
    "\n",
    "We are implementing a sliding windows that move on the whole image. The windows (=retina) is 36x36 pixels. In order to, find faces of all sizes we have to find to do it on multiple scale.\n",
    "\n",
    "For each scale, we will get an image of the prediction the neural network made (yes or no for that pixel).\n",
    "So we have to aggregate the result of each scale's image to one. Meaning we have to upscale the image.\n",
    "Then we will have to find \"blob\" in these image. Also we have to filter false alarm.\n",
    "\n",
    "False alarm can be filtered by considering the volume of the blob. False alarm tends to be smaller than True Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 0.8\n",
    "\n",
    "# while (True):\n",
    "#     new_height = transformed_image.size()[1] * scale\n",
    "#     new_width = transformed_image.size()[2] * scale\n",
    "\n",
    "#     # stop the loop if the image is smaller than the retina\n",
    "#     if new_height < 36 and new_width < 36:\n",
    "#         break\n",
    "\n",
    "#     transformed_image = T.Resize((math.ceil(new_height), math.ceil(new_width)), interpolation=InterpolationMode.BILINEAR)(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = transformed_image.clone()\n",
    "images = []\n",
    "\n",
    "scale = 0.8\n",
    "threshold = 0.5\n",
    "stride = 8\n",
    "\n",
    "feature_maps = []\n",
    "\n",
    "while (True):\n",
    "    images.append(image)\n",
    "    feature_map = []\n",
    "    for y in range(0, image.size()[1] - 36, stride):\n",
    "\n",
    "        feature_row = []\n",
    "        for x in range(0, image.size()[2] - 36, stride):\n",
    "\n",
    "            # crop and preparing the cropped image\n",
    "            new_img = image[:, y:y+36, x:x+36]\n",
    "            new_img = new_img.reshape((1, 1, 36, 36))\n",
    "\n",
    "            (y_pred, pred_probab) = predict(model, new_img)\n",
    "            \n",
    "            # 0 = noface, 1 = face\n",
    "            if(y_pred == 1 and (threshold == None or pred_probab.squeeze()[1] >= threshold)):\n",
    "                feature_row.append(True)\n",
    "                cv.rectangle(img_color, (x,y), (x+36,y+36), (255, 0, 0))\n",
    "            else:\n",
    "                feature_row.append(False)\n",
    "\n",
    "        feature_map.append(feature_row)\n",
    "\n",
    "    feature_maps.append(feature_map)\n",
    "    \n",
    "    new_height = math.ceil(image.size()[1] * scale)\n",
    "    new_width = math.ceil(image.size()[2] * scale)\n",
    "\n",
    "    # stop the loop if the image is smaller than the retina\n",
    "    if new_height < 36 or new_width < 36:\n",
    "        break\n",
    "\n",
    "    image = T.Resize((new_height, new_width), interpolation=InterpolationMode.BILINEAR)(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {0} boolean image.\".format(len(feature_maps)))\n",
    "\n",
    "for i, map in enumerate(feature_maps):\n",
    "    print(\"map {0} is of size {1} x {2}\".format(i, len(map), len(map[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing found feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 50))\n",
    "rows = math.ceil(len(feature_maps))\n",
    "cols = 5\n",
    "\n",
    "feature_maps_contours = []\n",
    "\n",
    "for i in range(0, len(feature_maps)):\n",
    "    map = feature_maps[i]\n",
    "    # Adds a subplot at the 1st position\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    \n",
    "    # showing image\n",
    "    image = torch.tensor(map)\n",
    "\n",
    "    image = image.reshape(len(map), len(map[0]), 1).numpy()\n",
    "    image = image*255\n",
    "    image = image.astype(np.uint8) # cv rectangle only accepts np.uint8 https://stackoverflow.com/questions/71762449/error-opencv4-5-4-1-error-5bad-argument-in-function-gaussianblur\n",
    "    \n",
    "    # finding contours of boids in the feature map\n",
    "    # contours, hierarchy = cv.findContours(image, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # for x in contours:\n",
    "    #     print(cv.boundingRect(x))\n",
    "\n",
    "    plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 50))\n",
    "rows = math.ceil(len(images))\n",
    "cols = 5\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    image = images[i]\n",
    "\n",
    "    # Adds a subplot at the 1st position\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    \n",
    "    # feature_map\n",
    "    feature = torch.tensor(feature_maps[i])\n",
    "    feature = feature.reshape((1, feature.size()[0], feature.size()[1]))\n",
    "    feature = T.Resize((image.size()[1], image.size()[2]), interpolation=InterpolationMode.BILINEAR)(feature)\n",
    "\n",
    "    feature = feature.permute(1, 2, 0).numpy()\n",
    "    feature = feature*255\n",
    "    feature = feature.astype(np.uint8)\n",
    "\n",
    "    plt.imshow(feature, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 50))\n",
    "rows = math.ceil(len(images))\n",
    "cols = 5\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    # Adds a subplot at the 1st position\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    \n",
    "    # showing image\n",
    "    image = images[i].permute(1, 2, 0).numpy()\n",
    "    image = (image*0.5 + 0.5)*255\n",
    "    image = image.astype(np.uint8) # cv rectangle only accepts np.uint8 https://stackoverflow.com/questions/71762449/error-opencv4-5-4-1-error-5bad-argument-in-function-gaussianblur\n",
    "    cv.rectangle(image, (0,0), (36, 36), (255,255,255))\n",
    "    plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 50))\n",
    "rows = math.ceil(len(images))\n",
    "cols = 5\n",
    "\n",
    "height = transformed_image.size()[1]\n",
    "width = transformed_image.size()[2]\n",
    "merge_feature = torch.zeros([1, height, width], dtype=torch.int64)\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    image = images[i]\n",
    "\n",
    "    # Adds a subplot at the 1st position\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    \n",
    "    # feature_map\n",
    "    feature = torch.tensor(feature_maps[i])\n",
    "    feature = feature.reshape((1, feature.size()[0], feature.size()[1]))\n",
    "    feature = T.Resize((image.size()[1], image.size()[2]), interpolation=InterpolationMode.BILINEAR)(feature)\n",
    "\n",
    "    fs_feature = T.Resize((height, width), interpolation=InterpolationMode.BILINEAR)(feature)\n",
    "    merge_feature = merge_feature + fs_feature\n",
    "    \n",
    "    # merge_feature = merge_feature + feature\n",
    "\n",
    "    feature = feature.permute(1, 2, 0).numpy()\n",
    "    feature = feature*255\n",
    "    feature = np.clip(feature, 0, 255)\n",
    "    feature = feature.astype(np.uint8)\n",
    "\n",
    "\n",
    "    # image\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    image = (image*0.5 + 0.5)*255\n",
    "    \n",
    "    image = image + feature\n",
    "    image = np.clip(image, 0, 255)\n",
    "\n",
    "    image = image.astype(np.uint8) # cv rectangle only accepts np.uint8 https://stackoverflow.com/questions/71762449/error-opencv4-5-4-1-error-5bad-argument-in-function-gaussianblur\n",
    "\n",
    "    plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "merge_feature = merge_feature * 255\n",
    "merge_feature = merge_feature.permute(1, 2, 0).numpy()\n",
    "merge_feature = np.clip(merge_feature, 0, 255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 50))\n",
    "rows = 1\n",
    "cols = 2\n",
    "\n",
    "fig.add_subplot(rows, cols, 1)\n",
    "plt.imshow(merge_feature, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "merge_image = transformed_image.clone().permute(1, 2, 0).numpy()*255\n",
    "\n",
    "merge_image = np.clip(merge_image + merge_feature*255, 0, 255)\n",
    "\n",
    "fig.add_subplot(rows, cols, 2)\n",
    "plt.imshow(merge_image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imshow(\"Display window\", img_color)\n",
    "# k = cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
