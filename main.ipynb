{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of the project is to recognize if the image is a face or not.\n",
    "\n",
    "Images are greyscale 36x36 pixels images.\n",
    "\n",
    "To reach the goal, we will try to train a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from deep_learning_project.load_data import basic_load, imbalanced_load\n",
    "from deep_learning_project.net import FirstNeuralNetwork, LinearRegressionNetwork, SecondNeuralNetwork\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from deep_learning_project.trainers import BaseTrainer\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from deep_learning_project.utils import Exporter\n",
    "\n",
    "CURRENT_FOLDER = '.'\n",
    "MODEL_FOLDERS = os.path.join(CURRENT_FOLDER, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is separated in 3 datasets.\n",
    "\n",
    "Train : to train the ML model.\n",
    "\n",
    "Valid : to valid the ML model.\n",
    "\n",
    "Test : to test the ML model.\n",
    "\n",
    "What is the difference between valid and test datasets. The main differencec is when there are used : valid are used inside the training process but test are used when the training is complete. Why use different datasets to do the same thing (test the generalization of model) ? Some do the validation with the test dataset but it is not scientifically correct because it will include a bias on the model. If we train the model until the test dataset error is the lowest, we effectively train the model for the test dataset... This is why we use two different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0. Parallel=False.\n",
      "{'num_workers': 4, 'pin_memory': True}\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "parallel = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        parallel = True\n",
    "\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "print(f\"Running on {device}. Parallel={parallel}.\")\n",
    "\n",
    "data = imbalanced_load(valid_size=valid_size, batch_size=batch_size, device=device)\n",
    "train_loader = data[0]\n",
    "valid_loader = data[1]\n",
    "test_loader = data[2]\n",
    "classes = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 36, 36])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data[0]))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze() # from 2d to 1d, works only when the data is 1d [[x]] => [x]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing one image of the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the FirstNeuralNetwork network\n",
    "\n",
    "We initialize the network.\n",
    "\n",
    "Print the configuration.\n",
    "\n",
    "Then predict a random input.\n",
    "\n",
    "---\n",
    "\n",
    "FirstNeuralNetwork is the neural network given by the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SecondNeuralNetwork(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 48, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=4800, out_features=48, bias=True)\n",
       "  (fc2): Linear(in_features=48, out_features=24, bias=True)\n",
       "  (fc3): Linear(in_features=24, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = SecondNeuralNetwork()\n",
    "if parallel:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "random_shit = torch.rand((1, 1, 36, 36), device=device)\n",
    "\n",
    "logits = model(random_shit)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter = Exporter()\n",
    "exporter.prepare_export(MODEL_FOLDERS, str(model.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "trainer = BaseTrainer(model, loss_fn, optimizer, checkpoints_path=exporter.folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset=73376, train batches=2293, valid dataset=18344, valid batches=574, test dataset=7628, test batches=239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 144.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 of 10 : train_loss: 0.45518, train_accuracy: 78.31%, valid_loss: 0.38682, valid_accuracy: 84.99%, test_loss: 0.15041, test_accuracy: 94.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 150.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 of 10 : train_loss: 0.18911, train_accuracy: 92.56%, valid_loss: 0.15162, valid_accuracy: 94.38%, test_loss: 0.08304, test_accuracy: 97.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 150.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 of 10 : train_loss: 0.07369, train_accuracy: 97.29%, valid_loss: 0.04632, valid_accuracy: 98.45%, test_loss: 0.03603, test_accuracy: 98.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 150.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 of 10 : train_loss: 0.04784, train_accuracy: 98.36%, valid_loss: 0.03845, valid_accuracy: 98.66%, test_loss: 0.04950, test_accuracy: 98.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 151.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 of 10 : train_loss: 0.03579, train_accuracy: 98.79%, valid_loss: 0.03151, valid_accuracy: 98.86%, test_loss: 0.04547, test_accuracy: 98.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 152.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 of 10 : train_loss: 0.02923, train_accuracy: 99.02%, valid_loss: 0.02755, valid_accuracy: 99.05%, test_loss: 0.05076, test_accuracy: 98.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 151.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 of 10 : train_loss: 0.02444, train_accuracy: 99.19%, valid_loss: 0.02549, valid_accuracy: 99.06%, test_loss: 0.04902, test_accuracy: 98.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:14, 153.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 of 10 : train_loss: 0.02110, train_accuracy: 99.27%, valid_loss: 0.02102, valid_accuracy: 99.26%, test_loss: 0.03808, test_accuracy: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 151.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 of 10 : train_loss: 0.01841, train_accuracy: 99.38%, valid_loss: 0.02596, valid_accuracy: 99.07%, test_loss: 0.06229, test_accuracy: 98.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:15, 148.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 of 10 : train_loss: 0.01660, train_accuracy: 99.46%, valid_loss: 0.01919, valid_accuracy: 99.29%, test_loss: 0.05700, test_accuracy: 98.53%\n",
      "CPU times: total: 2min 19s\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.fit(train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            test_loader=test_loader,\n",
    "            epochs=epochs,\n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file_data = {\n",
    "    \"device\": device,\n",
    "    \"network\": str(model.__class__.__name__),\n",
    "    \"epochs_number\": epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_len_data\": len(train_loader.dataset), \n",
    "    \"test_len_data\": len(test_loader.dataset),\n",
    "    \"trainer\": str(trainer.__class__.__name__),\n",
    "    \"optimizer\": str(optimizer.__class__.__name__),\n",
    "    \"pytorch_version\": torch.__version__,\n",
    "    \"loss_function\": str(loss_fn.__class__.__name__),\n",
    "    \"performances\" : trainer.get_stats(),\n",
    "}\n",
    "\n",
    "exporter.export_stat_file(stats_file_data)\n",
    "\n",
    "exporter.export_model(model, 'weights.pt')\n",
    "exporter.export_best_models(trainer.get_best_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# ld_model = torch.load('model.pt')\n",
    "\n",
    "# test_loop(test_loader, ld_model, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
