{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of the project is to recognize if the image is a face or not.\n",
    "\n",
    "Images are greyscale 36x36 pixels images.\n",
    "\n",
    "To reach the goal, we will try to train a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from deep_learning_project.load_data import basic_load, imbalanced_load\n",
    "from deep_learning_project.net import FirstNeuralNetwork, LinearRegressionNetwork, SecondNeuralNetwork\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from deep_learning_project.trainers import BaseTrainer\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from deep_learning_project.utils import Exporter\n",
    "\n",
    "CURRENT_FOLDER = '.'\n",
    "MODEL_FOLDERS = os.path.join(CURRENT_FOLDER, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "learning_rate=0.001\n",
    "momentum=0.90\n",
    "weight_decay=0\n",
    "valid_size=0.2\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is separated in 3 datasets.\n",
    "\n",
    "Train : to train the ML model.\n",
    "\n",
    "Valid : to valid the ML model.\n",
    "\n",
    "Test : to test the ML model.\n",
    "\n",
    "What is the difference between valid and test datasets. The main differencec is when there are used : valid are used inside the training process but test are used when the training is complete. Why use different datasets to do the same thing (test the generalization of model) ? Some do the validation with the test dataset but it is not scientifically correct because it will include a bias on the model. If we train the model until the test dataset error is the lowest, we effectively train the model for the test dataset... This is why we use two different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0. Parallel=False.\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "parallel = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        parallel = True\n",
    "\n",
    "print(f\"Running on {device}. Parallel={parallel}.\")\n",
    "\n",
    "data = imbalanced_load(valid_size=valid_size, batch_size=batch_size, device=device)\n",
    "train_loader = data[0]\n",
    "valid_loader = data[1]\n",
    "test_loader = data[2]\n",
    "classes = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 36, 36])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW5ElEQVR4nO3df2yd1XkH8O8TJ8H55TgOiWOFQEhBTAitQWKIQiUYjClUA1KpQmTaxCTUdFKRWq2axviHtlolKq1l/WNiAhrIpI4fAjoQYj9QVgkqDUoKhIaEkTRKhBPHJoEkdhI72H72x32NLvb5vr7n3ve998bn+5Gi2I/vfe97ru/jaz/nvM8xd4eIzH3zWn0CItIcSnaRRCjZRRKhZBdJhJJdJBFKdpFEzG/kzma2CcDPAHQAeNzdH8q7fWdnpy9btqz2k5sfPr1z584F42fOnAnGR0dHa35MAJg3L/wz0MyijpN3LDblGTsV2tnZGYwvX748Kr5o0aJg/MSJE8H4sWPHgvGRkZFgnD13bLyTk5PBeOz3ZmJiIhhvhqJeR7FjcPfgA1i98+xm1gHgQwC3AugH8BaALe6+h91n1apVvnnz5hlx9qSsXLkyGD948GAw/s477wTjH3zwATuloMWLFwfjLCHqOdbY2FhUnP3gu+KKK4Lx2267LSp+1VVXBeMvv/xyMP7YY48F46+//nowvmDBgmD8s88+C8bZD+7Y783JkyeD8Tzj4+PR9wlh58qeC+b06dPBODtPluyN/Bp/LYD97n7A3c8BeBrAnQ0cT0RK1EiyrwXwUdXn/VnsC8xsq5ntNLOdsb9Oi0hxSi/Qufuj7n6Nu1/D/r4UkfI1kuyHAayr+vyiLCYibaiRAt18VAp0t6CS5G8B+HN3f5/dZ8GCBd7T0zMjfsEFFwRv39HREYyzgh4r9pw6dSoYZ4WPhQsXBuP1YMUYNualS5cG46w6PTw8HIyz5+7GG28Mxjdt2hSM33777cE4s3379qh4rIGBgWA8ZpZnNqw4yIqn7HUXi80yxRgfH6cFurqn3tx93MzuA/BfqEy9bctLdBFprYbm2d39FQCvFHQuIlIiraATSYSSXSQRSnaRRNRdja/H/Pnzvbu7e0acLStklVdmyZIlUbePXYbIlqzmPS67T+xjsOo6q+oX5Y477gjGb7jhhmB8y5YtwThbY//4448H4+x7w5ZQHzlyJBhn68rZ85mHVenZ95JV79nYYqvxofzYtWsXRkZGCl8uKyLnESW7SCKU7CKJULKLJELJLpKIplbjY9fGM2ytO1ujXFSzACZvLX3sY8dW42PFXofAKtDMZZddFozffffdwfj1118fjLMGJXv37g3G2fnHNs0AeAWfxVnVveyZktDjPvHEExgYGFA1XiRlSnaRRCjZRRKhZBdJhJJdJBFtsTaerS1m1cyiOoaw9sPsfNjx89Y0s2OtXr06GGedalg/doYdh2Etl2NnAdj3pqurKxjfsGFDMM7627PjM6yCnjfLwGZ72PeAPQabCYjthMQatYY6NvX392NsbEzVeJGUKdlFEqFkF0mEkl0kEUp2kUQ0VI03s4MAhgFMABh392vybs/WxsdW12PXmxfV17sZYvvMFyV25iP2OKz6ffbs2WCczZSwrkasgl6P2O5CscdhipiVGhkZwfj4eLF946v8sbuH9+8VkbahX+NFEtFosjuA/zaz35rZ1iJOSETK0eiv8V9198NmthrAq2b2gbu/Vn2D7IfAVoDv0SYi5Wso+9z9cPb/EIBfArg2cJvPt2xWsou0Tt3v7Ga2BMA8dx/OPv5TAD/Mu8/k5GRwfTGrQMdW3YsS2787r0ob22s+toJbFFYtZ9VvVqVncbbGPnYNf2xXmCL7xseKfQx2ezaGWI28snoB/NLMpo7zb+7+n4WclYgUrpEtmw8A+HKB5yIiJdIf0SKJULKLJELJLpKI1pR+a9SqNe2xnURib1+kota0s0pwUZ1hWqWocQHF9fSPvRaEXSewbt26GbH9+/fTx9U7u0gilOwiiVCyiyRCyS6SCCW7SCLaohrfbp1kmrEmv+zKblFiq/1lrzmPrfaz29fT+Sf2uWBx9r1fsWJFMN7b2xuMh57rvOdf7+wiiVCyiyRCyS6SCCW7SCKU7CKJaGo13sxa1n0mpBldYZrRESWkqDXqebudhpQ93tjjs51X8zrkFNX7nr3Wly1bFnVOrKp//PjxGbG8Lkt6ZxdJhJJdJBFKdpFEKNlFEqFkF0mEkl0kEbPOPZnZNgB/BmDI3a/KYj0AngGwHsBBAHe5+6c1HCvqAoRWNvhvlXYbM3vc2AtJimpvFfs8xG5CAfApNrYZCHuM1atXB+Nsynd0dDQYHxoaqvlxs30cgmp5Z38SwKZpsfsB7HD3ywHsyD4XkTY2a7JnGzV+Mi18J4Dt2cfbAWwu9rREpGj1LiHrdfeB7OOjqGwFFaRdXEXaQ8PZ5+6Oyj7t7OvaxVWkDdSbfYNm1gcA2f/hCoKItI16f41/CcA9AB7K/n+xsDOq0m5V93bbACFP7FbLsdrtOO32WgHyt/IOYRexsJmP0CYRrHIP1PDObmZPAfhfAFeYWb+Z3YtKkt9qZvsA/En2uYi0sVnf2d19C/nSLQWfi4iUSBUzkUQo2UUSoWQXSURT21K5e6kV7djqJ8M2rainpVYzWl+FFLUWPfY5jR1v7GYZbJahs7MzGP/kk+mLPyvyXodszOx1weKsJRbbgpm1q2Kvu5MnT86I5Y1L7+wiiVCyiyRCyS6SCCW7SCKU7CKJaIstm5nYSvDp06cLOX6RFXS2rrnsdfax1XVWUWbdVtgVjAsXLgzGWbWcVddZfPny5cE46xZz9OjRYHzfvn3BOBDefAHgVXQ2c8C+B2xsbAwbNmwIxgcHB2fE8q4s1Tu7SCKU7CKJULKLJELJLpIIJbtIItqiGh/bZYRtkVuU2FmAJUuW0K+xNeqs+s2w9dFs5oBVrdesWROMswoxw44fOy723LE4m93o6uoKxlmFO1TJnsKq8bFit2ZeuXJlMM762IdmOBrtGy8ic4CSXSQRSnaRRCjZRRKhZBdJRL27uH4fwDcBfJzd7AF3f6Xek2AVa1Z5je0YE1vJjpVXvWdj6OvrC8Z7e8M7aV144YXBeOwuO5OTk8E466rCqtwMq/Z3d3cH4+x6htiqPqug79q1K+r2edisEauus+eOzWSw12nMHgCNro1/EjN3cQWAh919Y/av7kQXkeaodxdXETnPNPI3+31m9p6ZbTOzFexGZrbVzHaa2c7KHpAi0gr1JvsjAL4EYCOAAQA/YTes3sU1b3WPiJSrrmR390F3n3D3SQCPAbi22NMSkaLVVY42sz53H8g+/TqA3bXcb968eVFrsNmaYFZFZ3FWLWdxVkUN7ZoJAJdcckkwnoft2Mmq4seOHQvGYyu4bM05GwM7PuvHzqr9J06cCMY//fTTYDx2rT7rSLN///5gPG8Ghb2OYrvqxPa4j+1eFJrpyfvtuZapt6cA3ATgQjPrB/AggJvMbCMAB3AQwLeizlJEmq7eXVx/XsK5iEiJtIJOJBFKdpFEKNlFEtHUTjUTExNRa5JZJTh2zTHru816ojOhXTMBXpkGgOHh4WA8ti86W3Mee50AW3POrk9g1XJWdWd94xlW+WbjYlX3N954o5DHBeL7usdW79n1Egx7LkIzNNrFVUSU7CKpULKLJELJLpIIJbtIIppajV+4cCEuvvjiGfGenp7g7deuXRuMsyonq1qyivKePXuCcbYmnz0u6yID8PX0DOvcws6JVcVjq+5MbLcgtrafYZ1VhoaGgvEPP/wwGGfjir1eAuAdadh1Baw/fFHVeDa20MxW3rj0zi6SCCW7SCKU7CKJULKLJELJLpKIplbjFy9ejKuvvnpGnFU59+3bF4yzSjNbF8yqq6yKynq6M3k9zg8ePBh1rFhsbKziy+KxVXo2Znb9QOxxWIcZdh0Cm9Fhr4m8tfGsk0xs1T32ugWGzcSEZj7Y7Aygd3aRZCjZRRKhZBdJhJJdJBFKdpFE1NJKeh2AfwXQi0rr6Efd/Wdm1gPgGQDrUWknfZe7hxehZ8bGxnDgwIEZcVbBZVVRVv1kO4WOjo4G46yLDOtxXg82htgZhaLWtMceJ2+tdQircrPzYd979jywTjixa+NZRyCA76Qb28u+qB122Z4Bscev5dbjAL7n7lcCuA7At83sSgD3A9jh7pcD2JF9LiJtqpZdXAfc/e3s42EAewGsBXAngO3ZzbYD2FzSOYpIAaIW1ZjZegBXA3gTQG/VFlBHUfk1P3SfrQC2AvHNCEWkODX/0m9mSwE8D+C77n6q+mte2Ys5uB9z9S6uRa0oEpF4NSW7mS1AJdF/4e4vZOFBM+vLvt4HINxtQETaQi3VeENlb7e97v7Tqi+9BOAeAA9l/78427HOnTuHI0eOzIizd3y20ymrlreqkp3Xq5utXY997KKOz9ZZszGw9eCx3XzYzAer9l966aXBOKuUHzp0KBgfGBgIxvP+pGSVevY6ZTMrbCaAXQvCuhSx2aTQGPIq9LX8zX4DgL8E8DszezeLPYBKkj9rZvcCOATgrhqOJSItUssurr8GwDZ9vqXY0xGRsmgFnUgilOwiiVCyiySiLXZxja1yli2293k7PnZRaxpYFf3s2bPBOOv3vn79+mCcVY8/+uijYJzNxLDjsNcQq+oDfNalqF1/2bmyLjysSh/anbi/v5+ej97ZRRKhZBdJhJJdJBFKdpFEKNlFEtHUajzDKqaxVfp2u33efYrCHptVcIvC1paz9eBs7T1bYx+atQF4hZutN1+5cmUwnvd9YTMQbIaA9axn1wmwjjSDg4PBOBtbaAyVS1nC9M4ukgglu0gilOwiiVCyiyRCyS6SiLaoxrOONLFi19KXfft671OE2OaerDrNquuswwyrrrM467TDusXE7h7b1dUVjLNe7HnY2nXWSYZdD8DO9dSpU8E4G0Pouai0gwzTO7tIIpTsIolQsoskQskukgglu0giGtnF9fsAvgng4+ymD7j7K/WcRNnbQrFqf1GPW9RsQp6ynyNW5Wbx2DGzCjQbV9nXFOTtTsvW07P7sOeIzUAcPnw4GGdr5mP3EmBqmXqb2sX1bTNbBuC3ZvZq9rWH3f0fCzkTESlVLX3jBwAMZB8Pm9nULq4ich6J+pt92i6uAHCfmb1nZtvMbAW5z1Yz22lmO/Mm/EWkXI3s4voIgC8B2IjKO/9PQver3sU171pbESlX3bu4uvugu0+4+ySAxwBcW95pikij6t7F1cz6sr/nAeDrAHbXexJFdYwp6nEZdj5FVspZlbuoGQV2nLzqdAirWLNdX1n3F1alZ5VstlafdYWJ3eUWiN/FlT0Gq66zNfasmw87fmdn54xYWbu4bjGzjahMxx0E8K0ajiUiLdLILq51zamLSGtoBZ1IIpTsIolQsoskoi061TSjY0yZx8lT9hrv2A4zixYtCsZZNZ4dh1Ws16xZE4yzLiysis6q8ax6z2YZWIWbHQfg/dtD1W+AV8vZjryx1xWwMYTi6lQjIkp2kVQo2UUSoWQXSYSSXSQRSnaRRDR16m1ycjJq2qGoizzaUeyFLbFTbLEXgLDbs5ZIbNqSXeTBxsvGxab2YltDjY2NBeNsOgvgU29Lly4NxtmWyuyxGfZc5E0TTscuvgH0zi6SDCW7SCKU7CKJULKLJELJLpKIplbj582bF6w2x1bRy27RVKTYNlCxF6SwSjAT236KYZXm2FkA1kaJXSDDqs3sIpV6XivsuWZiL85hY4vdHvv06dMzYnmzDHpnF0mEkl0kEUp2kUQo2UUSMWuym1mnmf3GzHaZ2ftm9oMsfqmZvWlm+83sGTMrd5tREWmIzbb/WrZJxBJ3H8l2hvk1gO8A+BsAL7j702b2LwB2ufsjsxzLQxXH2Ao0q6TGVtfLPk7esYqaOWDHYe2nihJbdS9q22H2uLFV/bxZidhqfOztWYuurq6uqOOEntPdu3djZGQkuM/arO/sXjHVTGtB9s8B3AzguSy+HcDmqDMVkaaqda+3jmw3mCEArwL4PYAT7j7147Ef2sZZpK3VlOzZBo4bAVyEygaOf1DrA1Rv2VzfKYpIEaKq8e5+AsCvAHwFQLeZTf2xchGAw+Q+n2/Z3MiJikhjaqnGrzKz7uzjRQBuBbAXlaT/RnazewC8WNI5ikgBaikj9gHYbmYdqPxweNbdXzazPQCeNrN/APAOKts6zypUBWVdSVj3kbKr7kVV6Ys+VpliZ0Ty1mCHsE0fijofVqWvZyMQdiw2BjbTwK5bYOv7Y6+XCMXzvi+17OL6HoCrA/EDqPz9LiLnAa2gE0mEkl0kEUp2kUQo2UUS0dRONR0dHcHe26zTB1vX3G7yKuuxa+BjFbUlNKtax677LkpsFT22gl6Ps2fPRt2eVeNjt5FmXYFCuaS+8SKiZBdJhZJdJBFKdpFEKNlFEtHUUuvExESw4sjWxof6YgPx683LXgNfdsU9D6taszir3hdV1WdYtZxVpmN3rY3thJNXpWdr0Vn3n56enmCcva7ZTrcjIyPBONs9NvQ9zus8pXd2kUQo2UUSoWQXSYSSXSQRSnaRRDR9F9fQbpvt1h++qGp/M7CqcuyadlZpZpXp2Gp/bJ95hp0PWz9eZN/4ZcuWBeOs6s7OiWHfg5hqfB69s4skQskukgglu0gilOwiiVCyiyRi1pKtmXUCeA3ABdntn3P3B83sSQA3Apha7P5X7v5uPSfBOnQwRe2AGnv7etbAl72LK8Oqzax7SlHV8qLEVvtj5c1WsAo+2ymWVd1HR0ejjt/d3R2Ms3X/oWtHPv744+Btgdqm3sYA3Fy9ZbOZ/Uf2tb919+dy7isibaKWTSIcQGjLZhE5j9S1ZbO7v5l96Udm9p6ZPWxmwd81qndxzbv8TkTKVdeWzWZ2FYC/R2Xr5j8C0APg78h9P9/F1cyKOWsRiVbvls2b3H3AK8YAPAHt+ybS1mqpxq8C8Jm7n6jasvnHZtbn7gNWebveDGD3bMeanJw8dubMmUPZpxcCOFbPSeetay5Tg4/7hfG2agyxMx8Nqvt73ErHjx+v967tMN5L2Bca2bL5f7IfBAbgXQB/PduB3H3V1MfZ3/DX1PD4c0Jq4wXSG3O7j7eRLZtvLuWMRKQUWkEnkohWJvujLXzsVkhtvEB6Y27r8ZrmvkXSoF/jRRKhZBdJRNOT3cw2mdn/mdl+M7u/2Y/fDGa2zcyGzGx3VazHzF41s33Z/ytaeY5FMrN1ZvYrM9tjZu+b2Xey+Fwec6eZ/cbMdmVj/kEWv9TM3sxe38+YWeu2C5qmqcmezdX/M4DbAFwJYIuZXdnMc2iSJwFsmha7H8AOd78cwI7s87liHMD33P1KANcB+Hb2fZ3LY566GvTLADYC2GRm1wH4MYCH3f0yAJ8CuLd1p/hFzX5nvxbAfnc/4O7nADwN4M4mn0Pp3P01ANM39LoTwPbs4+2orDqcE7Kl029nHw8D2AtgLeb2mN3dQ1eD3gxg6rLvthpzs5N9LYCPqj7vz2Ip6HX3gezjowB6W3kyZTGz9agswnoTc3zM068GBfB7ACfcfWotdFu9vlWga4GsR8Ccm/M0s6UAngfwXXc/Vf21uTjm6VeDonIVaNtqdrIfBrCu6vOLslgKBs2sDwCy/4dafD6FyroYPQ/gF+7+Qhae02OeUnU16FcAdJvZ1DL0tnp9NzvZ3wJweVaxXAjgbgAvNfkcWuUlAPdkH98D4MUWnkuhsisffw5gr7v/tOpLc3nMq8ysO/t46mrQvagk/Teym7XVmJu+gs7MvgbgnwB0ANjm7j9q6gk0gZk9BeAmVC55HATwIIB/B/AsgIsBHAJwl7tPL+Kdl8zsqwBeB/A7AJNZ+AFU/m6fq2P+Q1QKcNVXg/7QzDagUnjuAfAOgL/Iej60nJbLiiRCBTqRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEqFkF0nE/wMWQTVmm8We0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data[0]))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze() # from 2d to 1d, works only when the data is 1d [[x]] => [x]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing one image of the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the FirstNeuralNetwork network\n",
    "\n",
    "We initialize the network.\n",
    "\n",
    "Print the configuration.\n",
    "\n",
    "Then predict a random input.\n",
    "\n",
    "---\n",
    "\n",
    "FirstNeuralNetwork is the neural network given by the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FirstNeuralNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = FirstNeuralNetwork()\n",
    "if parallel:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "random_shit = torch.rand((1, 1, 36, 36), device=device)\n",
    "\n",
    "logits = model(random_shit)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter = Exporter()\n",
    "exporter.prepare_export(MODEL_FOLDERS, str(model.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "trainer = BaseTrainer(model, loss_fn, optimizer, checkpoints_path=exporter.folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset=73376, train batches=1147, valid dataset=18344, valid batches=287, test dataset=7628, test batches=120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:40, 28.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 of 20 : train_loss: 0.26438, train_accuracy: 88.32%, valid_loss: 0.10932, valid_accuracy: 96.14%, test_loss: 0.14554, test_accuracy: 94.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:46, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 of 20 : train_loss: 0.08541, train_accuracy: 96.95%, valid_loss: 0.06108, valid_accuracy: 97.93%, test_loss: 0.09372, test_accuracy: 96.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:47, 24.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 of 20 : train_loss: 0.06192, train_accuracy: 97.82%, valid_loss: 0.05740, valid_accuracy: 97.98%, test_loss: 0.11291, test_accuracy: 96.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:29, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 of 20 : train_loss: 0.04899, train_accuracy: 98.28%, valid_loss: 0.05890, valid_accuracy: 98.01%, test_loss: 0.13820, test_accuracy: 95.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:21, 53.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 of 20 : train_loss: 0.04086, train_accuracy: 98.64%, valid_loss: 0.05718, valid_accuracy: 98.04%, test_loss: 0.11409, test_accuracy: 96.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:18, 63.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 of 20 : train_loss: 0.03762, train_accuracy: 98.74%, valid_loss: 0.04514, valid_accuracy: 98.37%, test_loss: 0.10545, test_accuracy: 96.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:17, 66.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 of 20 : train_loss: 0.03203, train_accuracy: 98.89%, valid_loss: 0.04595, valid_accuracy: 98.45%, test_loss: 0.12347, test_accuracy: 96.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 71.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 of 20 : train_loss: 0.02996, train_accuracy: 98.97%, valid_loss: 0.03384, valid_accuracy: 98.88%, test_loss: 0.08145, test_accuracy: 97.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:15, 72.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 of 20 : train_loss: 0.02753, train_accuracy: 99.08%, valid_loss: 0.04376, valid_accuracy: 98.65%, test_loss: 0.09894, test_accuracy: 97.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:17, 66.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 of 20 : train_loss: 0.02342, train_accuracy: 99.19%, valid_loss: 0.03586, valid_accuracy: 98.88%, test_loss: 0.09235, test_accuracy: 97.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 68.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 of 20 : train_loss: 0.02381, train_accuracy: 99.18%, valid_loss: 0.03375, valid_accuracy: 98.87%, test_loss: 0.07663, test_accuracy: 97.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 68.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 of 20 : train_loss: 0.02015, train_accuracy: 99.31%, valid_loss: 0.03180, valid_accuracy: 98.97%, test_loss: 0.09780, test_accuracy: 97.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:15, 72.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 of 20 : train_loss: 0.02039, train_accuracy: 99.33%, valid_loss: 0.03534, valid_accuracy: 98.78%, test_loss: 0.09485, test_accuracy: 97.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 68.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 of 20 : train_loss: 0.01774, train_accuracy: 99.39%, valid_loss: 0.02916, valid_accuracy: 98.98%, test_loss: 0.09068, test_accuracy: 97.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 68.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 of 20 : train_loss: 0.01558, train_accuracy: 99.47%, valid_loss: 0.03287, valid_accuracy: 98.95%, test_loss: 0.09633, test_accuracy: 97.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:18, 62.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 of 20 : train_loss: 0.01774, train_accuracy: 99.42%, valid_loss: 0.02861, valid_accuracy: 99.00%, test_loss: 0.10062, test_accuracy: 97.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 71.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 of 20 : train_loss: 0.01601, train_accuracy: 99.47%, valid_loss: 0.04353, valid_accuracy: 98.83%, test_loss: 0.09391, test_accuracy: 97.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:15, 73.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 of 20 : train_loss: 0.01350, train_accuracy: 99.57%, valid_loss: 0.03874, valid_accuracy: 98.80%, test_loss: 0.15275, test_accuracy: 96.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:15, 73.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 of 20 : train_loss: 0.01373, train_accuracy: 99.54%, valid_loss: 0.03663, valid_accuracy: 98.99%, test_loss: 0.08955, test_accuracy: 97.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1147it [00:16, 68.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 of 20 : train_loss: 0.01267, train_accuracy: 99.56%, valid_loss: 0.03279, valid_accuracy: 99.09%, test_loss: 0.11229, test_accuracy: 97.54%\n",
      "CPU times: total: 2min 52s\n",
      "Wall time: 19min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.fit(train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            test_loader=test_loader,\n",
    "            epochs=epochs,\n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file_data = {\n",
    "    \"device\": device,\n",
    "    \"network\": str(model.__class__.__name__),\n",
    "    \"epochs_number\": epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_len_data\": len(train_loader.dataset), \n",
    "    \"test_len_data\": len(test_loader.dataset),\n",
    "    \"trainer\": str(trainer.__class__.__name__),\n",
    "    \"optimizer\": str(optimizer.__class__.__name__),\n",
    "    \"pytorch_version\": torch.__version__,\n",
    "    \"loss_function\": str(loss_fn.__class__.__name__),\n",
    "    \"performances\" : trainer.get_stats(),\n",
    "}\n",
    "\n",
    "exporter.export_stat_file(stats_file_data)\n",
    "\n",
    "exporter.export_model(model, 'weights.pt')\n",
    "exporter.export_best_models(trainer.get_best_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# ld_model = torch.load('model.pt')\n",
    "\n",
    "# test_loop(test_loader, ld_model, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
