{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of the project is to recognize if the image is a face or not.\n",
    "\n",
    "Images are greyscale 36x36 pixels images.\n",
    "\n",
    "To reach the goal, we will try to train a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning_project.load_data import load\n",
    "from deep_learning_project.net import Net\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is separated in 3 datasets.\n",
    "\n",
    "Train : to train the ML model.\n",
    "\n",
    "Valid : to valid the ML model.\n",
    "\n",
    "Test : to test the ML model.\n",
    "\n",
    "What is the difference between valid and test datasets. The main differencec is when there are used : valid are used inside the training process but test are used when the training is complete. Why use different datasets to do the same thing (test the generalization of model) ? Some do the validation with the test dataset but it is not scientifically correct because it will include a bias on the model. If we train the model until the test dataset error is the lowest, we effectively train the model for the test dataset... This is why we use two different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on {device}.\")\n",
    "\n",
    "data = load()\n",
    "train_loader = data[0]\n",
    "valid_loader = data[1]\n",
    "test_loader = data[2]\n",
    "classes = data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing one image of the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([8, 1, 36, 36])\n",
      "Labels batch shape: torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data[0]))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze() # from 2d to 1d, works only when the data is 1d [[x]] => [x]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the network\n",
    "\n",
    "We initialize the network.\n",
    "\n",
    "Print the configuration.\n",
    "\n",
    "Then predict a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "Predicted class: tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "print(model)\n",
    "\n",
    "random_shit = torch.rand((1, 1, 36, 36), device=device)\n",
    "\n",
    "logits = model(random_shit)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 0.05\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.698951  [    0/91720]\n",
      "loss: 0.089285  [ 8000/91720]\n",
      "loss: 0.010873  [16000/91720]\n",
      "loss: 0.006118  [24000/91720]\n",
      "loss: 0.020308  [32000/91720]\n",
      "loss: 0.002673  [40000/91720]\n",
      "loss: 0.123980  [48000/91720]\n",
      "loss: 0.000467  [56000/91720]\n",
      "loss: 0.002845  [64000/91720]\n",
      "loss: 0.000074  [72000/91720]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.422149 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/91720]\n",
      "loss: 0.009099  [ 8000/91720]\n",
      "loss: 0.000644  [16000/91720]\n",
      "loss: 0.000114  [24000/91720]\n",
      "loss: 0.109579  [32000/91720]\n",
      "loss: 0.001309  [40000/91720]\n",
      "loss: 0.000030  [48000/91720]\n",
      "loss: 0.006293  [56000/91720]\n",
      "loss: 0.000120  [64000/91720]\n",
      "loss: 0.016093  [72000/91720]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.491398 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.000950  [    0/91720]\n",
      "loss: 0.000007  [ 8000/91720]\n",
      "loss: 0.000111  [16000/91720]\n",
      "loss: 0.000106  [24000/91720]\n",
      "loss: 0.000001  [32000/91720]\n",
      "loss: 0.000118  [40000/91720]\n",
      "loss: 0.000002  [48000/91720]\n",
      "loss: 0.000022  [56000/91720]\n",
      "loss: 0.000018  [64000/91720]\n",
      "loss: 0.000008  [72000/91720]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.650114 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.002004  [    0/91720]\n",
      "loss: 0.000046  [ 8000/91720]\n",
      "loss: 0.002333  [16000/91720]\n",
      "loss: 0.000049  [24000/91720]\n",
      "loss: 0.000117  [32000/91720]\n",
      "loss: 0.000003  [40000/91720]\n",
      "loss: 0.000005  [48000/91720]\n",
      "loss: 0.021966  [56000/91720]\n",
      "loss: 0.010391  [64000/91720]\n",
      "loss: 0.000006  [72000/91720]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.470609 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000132  [    0/91720]\n",
      "loss: 0.000000  [ 8000/91720]\n",
      "loss: 0.000163  [16000/91720]\n",
      "loss: 0.000010  [24000/91720]\n",
      "loss: 0.000180  [32000/91720]\n",
      "loss: 0.001600  [40000/91720]\n",
      "loss: 0.000002  [48000/91720]\n",
      "loss: 0.014579  [56000/91720]\n",
      "loss: 0.000003  [64000/91720]\n",
      "loss: 0.003427  [72000/91720]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.450705 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
