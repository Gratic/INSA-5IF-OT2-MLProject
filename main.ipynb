{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of the project is to recognize if the image is a face or not.\n",
    "\n",
    "Images are greyscale 36x36 pixels images.\n",
    "\n",
    "To reach the goal, we will try to train a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from deep_learning_project.load_data import basic_load\n",
    "from deep_learning_project.net import FirstNeuralNetwork, LinearRegressionNetwork, SecondNeuralNetwork\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from deep_learning_project.trainers import BaseTrainer\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "CURRENT_FOLDER = '.'\n",
    "MODEL_FOLDERS = os.path.join(CURRENT_FOLDER, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is separated in 3 datasets.\n",
    "\n",
    "Train : to train the ML model.\n",
    "\n",
    "Valid : to valid the ML model.\n",
    "\n",
    "Test : to test the ML model.\n",
    "\n",
    "What is the difference between valid and test datasets. The main differencec is when there are used : valid are used inside the training process but test are used when the training is complete. Why use different datasets to do the same thing (test the generalization of model) ? Some do the validation with the test dataset but it is not scientifically correct because it will include a bias on the model. If we train the model until the test dataset error is the lowest, we effectively train the model for the test dataset... This is why we use two different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0. Parallel=False.\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "parallel = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        parallel = True\n",
    "\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "print(f\"Running on {device}. Parallel={parallel}.\")\n",
    "\n",
    "data = basic_load(valid_size=valid_size, batch_size=batch_size, device=device)\n",
    "train_loader = data[0]\n",
    "valid_loader = data[1]\n",
    "test_loader = data[2]\n",
    "classes = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 36, 36])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(data[0]))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze() # from 2d to 1d, works only when the data is 1d [[x]] => [x]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:28, 80.70it/s]\n",
      "574it [00:06, 83.67it/s]\n",
      "239it [00:02, 80.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading to gpu\n",
    "for i, data in tqdm(enumerate(train_loader, 0)):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "for i, data in tqdm(enumerate(valid_loader, 0)):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "for i, data in tqdm(enumerate(test_loader, 0)):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing one image of the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the FirstNeuralNetwork network\n",
    "\n",
    "We initialize the network.\n",
    "\n",
    "Print the configuration.\n",
    "\n",
    "Then predict a random input.\n",
    "\n",
    "---\n",
    "\n",
    "FirstNeuralNetwork is the neural network given by the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SecondNeuralNetwork(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 48, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=4800, out_features=48, bias=True)\n",
       "  (fc2): Linear(in_features=48, out_features=24, bias=True)\n",
       "  (fc3): Linear(in_features=24, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "model = SecondNeuralNetwork()\n",
    "if parallel:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "random_shit = torch.rand((1, 1, 36, 36), device=device)\n",
    "\n",
    "logits = model(random_shit)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_now = datetime.datetime.now()\n",
    "model_folder_name = os.path.join(MODEL_FOLDERS, date_now.strftime(\"%Y%m%d_%H%M\") + '_' + str(model.__class__.__name__))\n",
    "os.makedirs(model_folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "trainer = BaseTrainer(model, loss_fn, optimizer, checkpoints_path=model_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset=73376, train batches=2293, valid dataset=18344, valid batches=574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 62.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 of 20: train_loss: 0.26666, train_accuracy: 88.82%, valid_loss: 0.11171, valid_accuracy: 95.97%, test_loss: 0.57049, test_accuracy: 88.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 62.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 of 20: train_loss: 0.07242, train_accuracy: 97.46%, valid_loss: 0.03975, valid_accuracy: 98.78%, test_loss: 0.41839, test_accuracy: 90.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 62.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 of 20: train_loss: 0.03384, train_accuracy: 98.84%, valid_loss: 0.02738, valid_accuracy: 99.09%, test_loss: 0.31772, test_accuracy: 92.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 62.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 of 20: train_loss: 0.02197, train_accuracy: 99.27%, valid_loss: 0.01787, valid_accuracy: 99.40%, test_loss: 0.34524, test_accuracy: 93.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 62.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 of 20: train_loss: 0.01621, train_accuracy: 99.45%, valid_loss: 0.01282, valid_accuracy: 99.59%, test_loss: 0.30186, test_accuracy: 93.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 63.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 of 20: train_loss: 0.01306, train_accuracy: 99.57%, valid_loss: 0.01546, valid_accuracy: 99.44%, test_loss: 0.22937, test_accuracy: 94.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 of 20: train_loss: 0.01093, train_accuracy: 99.63%, valid_loss: 0.00968, valid_accuracy: 99.67%, test_loss: 0.34596, test_accuracy: 93.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 of 20: train_loss: 0.00892, train_accuracy: 99.71%, valid_loss: 0.00799, valid_accuracy: 99.73%, test_loss: 0.28316, test_accuracy: 94.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 of 20: train_loss: 0.00800, train_accuracy: 99.73%, valid_loss: 0.00904, valid_accuracy: 99.67%, test_loss: 0.38324, test_accuracy: 93.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 of 20: train_loss: 0.00665, train_accuracy: 99.78%, valid_loss: 0.00852, valid_accuracy: 99.72%, test_loss: 0.46555, test_accuracy: 93.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 of 20: train_loss: 0.00573, train_accuracy: 99.81%, valid_loss: 0.00821, valid_accuracy: 99.73%, test_loss: 0.31363, test_accuracy: 94.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 63.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 of 20: train_loss: 0.00487, train_accuracy: 99.84%, valid_loss: 0.00565, valid_accuracy: 99.83%, test_loss: 0.41440, test_accuracy: 93.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 62.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 of 20: train_loss: 0.00450, train_accuracy: 99.84%, valid_loss: 0.00606, valid_accuracy: 99.79%, test_loss: 0.34421, test_accuracy: 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:36, 63.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 of 20: train_loss: 0.00424, train_accuracy: 99.86%, valid_loss: 0.00579, valid_accuracy: 99.82%, test_loss: 0.32305, test_accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 of 20: train_loss: 0.00337, train_accuracy: 99.89%, valid_loss: 0.00548, valid_accuracy: 99.81%, test_loss: 0.25623, test_accuracy: 95.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 of 20: train_loss: 0.00324, train_accuracy: 99.88%, valid_loss: 0.00589, valid_accuracy: 99.82%, test_loss: 0.41036, test_accuracy: 94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 of 20: train_loss: 0.00274, train_accuracy: 99.90%, valid_loss: 0.00695, valid_accuracy: 99.78%, test_loss: 0.39529, test_accuracy: 94.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 of 20: train_loss: 0.00294, train_accuracy: 99.89%, valid_loss: 0.00476, valid_accuracy: 99.83%, test_loss: 0.36881, test_accuracy: 94.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 of 20: train_loss: 0.00208, train_accuracy: 99.94%, valid_loss: 0.00549, valid_accuracy: 99.81%, test_loss: 0.53959, test_accuracy: 93.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2293it [00:35, 64.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 of 20: train_loss: 0.00196, train_accuracy: 99.95%, valid_loss: 0.00744, valid_accuracy: 99.78%, test_loss: 0.40543, test_accuracy: 94.13%\n",
      "CPU times: total: 16min\n",
      "Wall time: 16min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.fit(train_loader=train_loader,\n",
    "            valid_loader=valid_loader,\n",
    "            test_loader=test_loader,\n",
    "            epochs=epochs,\n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15min31 with no grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = trainer.get_best_model()\n",
    "\n",
    "stats_file_data = {\n",
    "    \"device\": device,\n",
    "    \"network\": str(model.__class__.__name__),\n",
    "    \"epochs_number\": epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_len_data\": len(train_loader.dataset), \n",
    "    \"test_len_data\": len(test_loader.dataset),\n",
    "    \"trainer\": str(trainer.__class__.__name__),\n",
    "    \"optimizer\": str(optimizer.__class__.__name__),\n",
    "    \"pytorch_version\": torch.__version__,\n",
    "    \"loss_function\": str(loss_fn.__class__.__name__),\n",
    "    \"best_valid_epoch\": best_models['valid']['epoch'],\n",
    "    \"best_valid_accuracy\": best_models['valid']['accuracy'],\n",
    "    \"best_valid_loss\": best_models['valid']['loss'],\n",
    "    \"best_test_epoch\": best_models['test']['epoch'],\n",
    "    \"best_test_accuracy\": best_models['test']['accuracy'],\n",
    "    \"best_test_loss\": best_models['test']['loss'],\n",
    "    \"performances\" : trainer.get_stats(),\n",
    "}\n",
    "\n",
    "stats_file_data_json = json.dumps(stats_file_data, indent=4)\n",
    "\n",
    "stat_file_name = os.path.join(model_folder_name, 'stats.json')\n",
    "model_file_name = os.path.join(model_folder_name, 'weights.pt')\n",
    "best_valid_model_file_name = os.path.join(model_folder_name, 'best_valid_weights.pt')\n",
    "best_test_model_file_name = os.path.join(model_folder_name, 'best_test_weights.pt')\n",
    "\n",
    "with open(os.path.normpath(stat_file_name), 'w', encoding = 'utf-8') as file:\n",
    "    file.write(stats_file_data_json)\n",
    "\n",
    "torch.save(model.state_dict(), model_file_name)\n",
    "torch.save(best_models['valid']['model'], best_valid_model_file_name)\n",
    "torch.save(best_models['test']['model'], best_test_model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# ld_model = torch.load('model.pt')\n",
    "\n",
    "# test_loop(test_loader, ld_model, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
